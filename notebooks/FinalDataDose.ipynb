{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import re\n","import os\n","from datetime import datetime\n","\n","# =============================================================================\n","# Configuration - Google Colab Version\n","# =============================================================================\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","\n","# ── تعديل هنا: ضع المسار الصح بتاع folder الـ project عندك ──────────────\n","# مثال: لو الملف عندك في MyDrive مباشرة:\n","#   BASE_DIR = '/content/drive/MyDrive'\n","# أو لو في فولدر اسمه DataDoseDepi:\n","#   BASE_DIR = '/content/drive/MyDrive/DataDoseDepi'\n","BASE_DIR    = '/content/drive/MyDrive/DataDoseDepi'          # ← غيّر ده\n","\n","INPUT_FILE  = os.path.join(BASE_DIR, 'DataDoseDataset.csv')   # ← اسم ملف الـ input\n","OUTPUT_FILE = os.path.join(BASE_DIR, 'DataDoseDataset_CleanedDrugs.csv')\n","LOG_FILE    = os.path.join(BASE_DIR, 'cleaning_logFinal.txt')\n","\n","# للتأكد من المسار قبل التشغيل، شغّل الـ cell دي أول:\n","# import os\n","# print(os.listdir('/content/drive/MyDrive'))          # شوف الفولدرات الموجودة\n","# print(os.listdir(BASE_DIR))                          # تأكد إن الملف موجود\n","\n","# =============================================================================\n","# P0 — Immutable Principles\n","# P0.1: Synonym merging is FORBIDDEN (paracetamol ↔ acetaminophen must stay as-is)\n","# P0.2: Duplicate rows across the dataset are allowed; only intra-row deduplication\n","# =============================================================================\n","\n","# =============================================================================\n","# Encoded Token Decoder\n","# Handles __INGxxxx__ placeholders left by upstream encoding corruption.\n","# Add known mappings here as you discover them from your data.\n","# =============================================================================\n","ENCODED_TOKEN_MAP = {\n","    \"__ING0024__\": \"vita\",   # __ING0024__mins       → vitamins (filtered later)\n","    \"__ING0035__\": \"\",       # __ING0035__2           → bare \"2\" (filtered later)\n","    \"__ING0055__\": \"iron\",   # sp__ING0055__olactone → spironolactone\n","}\n","\n","# =============================================================================\n","# Garbage Terms (Exact-match only — no substring matching)\n","# =============================================================================\n","GARBAGE_LIST = [\n","    \"invalid\", \"test\", \"unknown\", \"no active ingredient\", \"pending\", \"deleted\",\n","    \"n/a\", \"not available\", \"natural source\", \"mixed\",\n","    \"coming soon\", \"special\", \"bitten\", \"mental\",\n","    \"herbal formula\", \"regurgitation milk formula\", \"gasmin odor\",\n","    \"ethyhexyl\", \"stearly alcohol\", \"silicones\",\n","    \"glycerol stearate\", \"octadeceny ammonium\",\n","    \"distearoylethyl hydroxyethylmonium methosulfate\",\n","    \"capramidopropylbetaine\", \"capryl\", \"cocoamidopropyl betaine\",\n","    \"water\", \"aqua\",\n","    \"dr ey t\", \"dr ey\",\n","    \"gereinigter honig\", \"selected theraputically active\",\n","    \"theraputically active\", \"gereinigter\", \"honig\",\n","    \"selected theraputically\",\n","    \"vitamins\", \"vita\", \"350m\",\n","]\n","GARBAGE_EXACT = set(x.strip().lower() for x in GARBAGE_LIST)\n","\n","# Short tokens that are garbage ONLY when they appear as a complete standalone token\n","GARBAGE_TOKENS_EXACT = {\n","    \"na\", \"n/a\", \"amin\", \"amins\", \"type\", \"formula\",\n","    \"other\", \"high\", \"pre\", \"mixed\", \"special\",\n","    \"as\", \"ivay\", \"potat\", \"len\",\n","    \"2\",\n","    # \"vitamin\" alone (no name after it) is a decode artifact from __ING0024__mins\n","    \"vitamin\",\n","}\n","\n","# =============================================================================\n","# NON-DRUG TOKENS — Supplements/marketing terms that are NOT active ingredients\n","# These are removed as individual tokens (not whole-row deletion).\n","# The remaining valid tokens in the same row are kept.\n","# Add more here as you discover them in your data.\n","# =============================================================================\n","NON_DRUG_TOKENS = {\n","    # Q10 variants\n","    \"q10\", \"coq10\", \"q 10\",\n","    # Bee products\n","    \"royal jelly\", \"propolis\", \"bee pollen\", \"bee wax\",\n","    # Vague antioxidant/supplement terms\n","    \"antioxidants\", \"antioxidant\",\n","    \"green tea extract\", \"grape seed extract\", \"pine bark extract\",\n","    \"ginkgo biloba\", \"ginseng\",\n","    # Vague food/cosmetic terms\n","    \"honey\", \"beeswax\", \"aloe vera\", \"aloe\",\n","    # Marketing/non-specific\n","    \"herbal extract\", \"plant extract\", \"natural extract\",\n","    \"amino acids blend\", \"protein blend\", \"mineral blend\",\n","    # Herbs / spices (not active pharmaceutical ingredients)\n","    \"turmeric\", \"curcumin\", \"ginger\", \"ginger extract\",\n","    \"garlic\", \"garlic extract\", \"garlic powder\",\n","    \"cinnamon\", \"cinnamon extract\",\n","    \"black seed\", \"black seed oil\", \"nigella sativa\",\n","    \"evening primrose\", \"evening primrose oil\",\n","    \"flaxseed\", \"flaxseed oil\", \"fish oil\",\n","    \"peppermint\", \"peppermint oil\",\n","    \"chamomile\", \"chamomile extract\",\n","    \"echinacea\", \"valerian\", \"ashwagandha\",\n","    # MSM (methylsulfonylmethane) — supplement, not pharmaceutical\n","    \"msm\", \"methylsulfonylmethane\",\n","    # Other common supplement-only terms\n","    \"lutein\", \"zeaxanthin\", \"lycopene\", \"astaxanthin\",\n","    \"resveratrol\", \"quercetin\",\n","    \"spirulina\", \"chlorella\",\n","    \"milk thistle\",\n","}\n","\n","# =============================================================================\n","# R4 — Spell-fix Dictionary (ONLY true typos — NO synonym merging per P0.1!)\n","# FORBIDDEN: acetaminophen ↔ paracetamol\n","# Keys are sorted longest-first so longer matches win over shorter substrings.\n","# =============================================================================\n","SPELL_FIX = {\n","    # Typos only — multi-word first\n","    \"benzylpenicillin sodiium\":  \"benzylpenicillin sodium\",\n","    # Single-word typos\n","    \"cholorohexidine\":           \"chlorhexidine\",\n","    \"chlorohexidine\":            \"chlorhexidine\",\n","    \"chlorohexidin\":             \"chlorhexidine\",\n","    \"nitrofurantion\":            \"nitrofurantoin\",\n","    \"immunoglobulins\":           \"immunoglobulin\",\n","    \"panthenoll\":                \"panthenol\",\n","    \"pantheno\":                  \"panthenol\",\n","    \"pilocarpin\":                \"pilocarpine\",\n","    \"macrophages\":               \"macrophage\",\n","    \"macrofage\":                 \"macrophage\",\n","    \"olanzapin\":                 \"olanzapine\",\n","    \"diclofienac\":               \"diclofenac\",\n","    \"sildeanfil\":                \"sildenafil\",\n","    \"sindalfil\":                 \"sildenafil\",\n","    \"digoxine\":                  \"digoxin\",\n","}\n","\n","# =============================================================================\n","# Manual Replacements — Applied BEFORE generic split\n","# B-vitamin codes use word-boundary regex to prevent b1 matching inside b12.\n","# Order: longest pattern first (b12 before b1, b9 before b3, etc.)\n","# =============================================================================\n","# Plain string replacements (applied first)\n","PLAIN_REPLACEMENTS = {\n","    \"vit.\":          \"vitamin \",\n","    \"vitamin b complex\": (\n","        \"thiamine + riboflavin + niacin + pantothenic acid + \"\n","        \"pyridoxine + biotin + folic acid + cobalamin\"\n","    ),\n","    \"b complex\": (\n","        \"thiamine + riboflavin + niacin + pantothenic acid + \"\n","        \"pyridoxine + biotin + folic acid + cobalamin\"\n","    ),\n","}\n","\n","# Regex word-boundary replacements for B-vitamin codes (order: longest first)\n","BVITAMIN_REGEX = [\n","    (re.compile(r'\\bvit\\b\\.?'),  \"vitamin \"),   # vit → vitamin\n","    (re.compile(r'\\bb12\\b'),     \"cobalamin\"),\n","    (re.compile(r'\\bb9\\b'),      \"folic acid\"),\n","    (re.compile(r'\\bb7\\b'),      \"biotin\"),\n","    (re.compile(r'\\bb6\\b'),      \"pyridoxine\"),\n","    (re.compile(r'\\bb5\\b'),      \"pantothenic acid\"),\n","    (re.compile(r'\\bb3\\b'),      \"niacin\"),\n","    (re.compile(r'\\bb2\\b'),      \"riboflavin\"),\n","    (re.compile(r'\\bb1\\b'),      \"thiamine\"),\n","]\n","\n","# Keep REPLACEMENTS as alias for backward-compat (not used in new apply fn)\n","REPLACEMENTS = PLAIN_REPLACEMENTS\n","\n","# =============================================================================\n","# Known Ingredient Vocabulary — Used for garbage phrase & unknown token detection\n","# =============================================================================\n","KNOWN_INGREDIENT_KEYWORDS = {\n","    \"vitamin\", \"acid\", \"calcium\", \"magnesium\", \"zinc\", \"iron\", \"sodium\",\n","    \"potassium\", \"chloride\", \"oxide\", \"hydrochloride\", \"sulfate\", \"phosphate\",\n","    \"gluconate\", \"citrate\", \"acetate\", \"lactate\", \"carbonate\", \"nitrate\",\n","    \"immunoglobulin\", \"albumin\", \"insulin\", \"heparin\", \"factor\", \"hormone\",\n","    \"enzyme\", \"extract\", \"compound\", \"complex\", \"analog\", \"analogue\",\n","    \"colony\", \"stimulating\", \"granulocyte\", \"macrophage\", \"ketoanalogue\",\n","    \"histidine\", \"lysine\", \"threonine\", \"tryptophan\", \"tyrosine\", \"amino\",\n","    \"iodo\", \"chloro\", \"hydroxy\", \"quinoline\", \"biotin\", \"niacin\", \"riboflavin\",\n","    \"pantothenic\", \"pyridoxine\", \"thiamine\", \"cobalamin\", \"folic\", \"selenium\",\n","    \"manganese\", \"copper\", \"boron\", \"chromium\", \"molybdenum\", \"fluoride\",\n","    \"iodochlorohydroxyquinoline\", \"panthenol\", \"pilocarpine\", \"omega\",\n","    \"retinol\", \"tocopherol\", \"ascorbic\", \"cholecalciferol\", \"ergocalciferol\",\n","    \"menadione\", \"phytomenadione\", \"alpha\", \"beta\", \"gamma\", \"delta\",\n","    \"methionine\", \"cysteine\", \"arginine\", \"leucine\", \"isoleucine\", \"valine\",\n","    \"alanine\", \"glycine\", \"proline\", \"serine\", \"glutamine\", \"asparagine\",\n","    \"aspartate\", \"glutamate\", \"phenylalanine\",\n","    \"coenzyme\", \"ubiquinone\", \"carnitine\", \"taurine\", \"inositol\", \"choline\",\n","    \"lipoic\", \"rutin\", \"hesperidin\", \"quercetin\", \"flavonoid\",\n","    \"glucosamine\", \"chondroitin\", \"collagen\", \"hyaluronic\",\n","    \"probiotic\", \"prebiotic\", \"lactobacillus\", \"bifidobacterium\",\n","    \"interferon\", \"erythropoietin\", \"filgrastim\", \"pegfilgrastim\",\n","    \"antitoxin\", \"antivenom\", \"vaccine\",\n","    \"paracetamol\", \"acetaminophen\", \"ibuprofen\", \"aspirin\", \"caffeine\",\n","    \"codeine\", \"morphine\", \"tramadol\", \"diclofenac\", \"naproxen\",\n","    \"amoxicillin\", \"ampicillin\", \"penicillin\", \"cephalexin\", \"azithromycin\",\n","    \"ciprofloxacin\", \"metronidazole\", \"doxycycline\", \"tetracycline\",\n","    \"metformin\", \"glibenclamide\", \"atorvastatin\", \"simvastatin\",\n","    \"amlodipine\", \"enalapril\", \"losartan\", \"hydrochlorothiazide\", \"furosemide\",\n","    \"omeprazole\", \"ranitidine\", \"metoclopramide\", \"domperidone\", \"ondansetron\",\n","    \"salbutamol\", \"terbutaline\", \"beclomethasone\", \"fluticasone\", \"ipratropium\",\n","    \"prednisolone\", \"dexamethasone\", \"hydrocortisone\", \"betamethasone\",\n","    \"loratadine\", \"cetirizine\", \"diphenhydramine\", \"promethazine\",\n","    \"diazepam\", \"alprazolam\", \"lorazepam\", \"clonazepam\", \"phenobarbital\",\n","    \"haloperidol\", \"risperidone\", \"olanzapine\", \"quetiapine\", \"aripiprazole\",\n","    \"fluoxetine\", \"sertraline\", \"paroxetine\", \"escitalopram\", \"venlafaxine\",\n","    \"levothyroxine\", \"propylthiouracil\", \"methimazole\",\n","    \"warfarin\", \"enoxaparin\", \"clopidogrel\",\n","    \"cyclosporine\", \"tacrolimus\", \"mycophenolate\", \"azathioprine\",\n","    \"methotrexate\", \"cyclophosphamide\", \"doxorubicin\", \"fluorouracil\",\n","    \"sildenafil\", \"tadalafil\", \"testosterone\", \"estradiol\", \"progesterone\",\n","    \"spironolactone\", \"dandelion\", \"silymarin\", \"iodine\",\n","    # Vaccine / biologic types\n","    \"poliomyelitis\", \"inactivated\", \"attenuated\", \"poliovirus\",\n","    \"willebrand\", \"von\",\n","}\n","\n","# =============================================================================\n","# R5 — Cosmetic / Personal-Care Terms\n","# Row is DELETED if 2+ of these terms are found in the entry.\n","# =============================================================================\n","COSMETIC_TERMS = {\n","    \"cream\", \"shampoo\", \"lotion\", \"styling\", \"smooth\", \"hair\", \"gel\",\n","    \"serum\", \"moisturizer\", \"conditioner\", \"spray\", \"foam\", \"mask\",\n","    \"scrub\", \"toner\", \"cleanser\", \"balm\", \"wax\", \"polish\",\n","    \"blush\", \"foundation\", \"lipstick\", \"mascara\", \"perfume\",\n","    \"fragrance\", \"deodorant\", \"sunscreen\", \"exfoliant\", \"primer\",\n","    \"scalp\", \"skin\", \"whitening\", \"regen\", \"matrix\", \"photostable\",\n","    \"uva\", \"uvb\",\n","}\n","\n","# =============================================================================\n","# R6 — Vague Category Terms (Keep row + flag = VAGUE_CATEGORY)\n","# =============================================================================\n","VAGUE_CATEGORY_EXACT = {\n","    \"minerals\", \"elements\", \"omega\", \"ors\", \"carbohydrates\",\n","    \"proteins\", \"multivitamin\", \"multivitamins\",\n","    \"vitamins and minerals\", \"vitamins\", \"trace elements\",\n","}\n","\n","# =============================================================================\n","# R7 — Truncated Token Detection (Keep row + flag = TRUNCATED)\n","# =============================================================================\n","TRUNCATED_TOKENS = {\n","    \"ethinyl\", \"mono\", \"hydro\", \"peg\", \"poly\",\n","    \"micronized alpha\", \"micronized\", \"dehydro\", \"desoxy\", \"nor\",\n","}\n","\n","# =============================================================================\n","# R8 — Unknown Token Detection\n","# token_flag = UNKNOWN  →  row_flag = HAS_UNKNOWN_TOKENS\n","# =============================================================================\n","# Tokens that are short but VALID (vitamin codes, acronyms, roman numerals, etc.)\n","SHORT_VALID_TOKENS = {\n","    \"a\", \"c\", \"d\", \"e\", \"k\",\n","    \"d2\", \"d3\", \"k1\", \"k2\", \"k3\",\n","    \"b1\", \"b2\", \"b3\", \"b5\", \"b6\", \"b7\", \"b9\", \"b12\",\n","    \"ors\", \"rna\", \"dna\", \"hiv\", \"ige\", \"igg\", \"iga\", \"igm\",\n","    \"atp\", \"adp\", \"nad\", \"gmp\", \"amp\",\n","    \"viii\", \"vii\", \"vi\", \"iv\", \"xii\", \"xiii\",\n","}\n","\n","# Pattern: matches suspicious/unknown token shapes\n","UNKNOWN_TOKEN_PATTERN = re.compile(\n","    r'^[a-z]{1,3}\\d+$'                   # c14, c16, peg4\n","    r'|^[a-z0-9]{1,3}\\s[a-z0-9]{1,2}$'  # \"g o\", \"wht x\"\n",")\n","\n","# =============================================================================\n","# Safe vitamin letters/codes — single-letter tokens that are valid vitamins\n","# =============================================================================\n","VALID_VITAMIN_LETTERS = {\n","    \"a\", \"c\", \"d\", \"e\", \"k\",\n","    \"d2\", \"d3\", \"k1\", \"k2\", \"k3\",\n","    \"b1\", \"b2\", \"b3\", \"b5\", \"b6\", \"b7\", \"b9\", \"b12\",\n","}\n","\n","# =============================================================================\n","# Pattern for inserting '+' between unseparated known ingredients\n","# =============================================================================\n","_UNSEP = (\n","    r'calcium|magnesium|zinc|iron|selenium|manganese|copper|boron|chromium|'\n","    r'molybdenum|fluoride|biotin|niacin|riboflavin|thiamine|pyridoxine|'\n","    r'pantothenic|folic|cobalamin|lysine|histidine|threonine|tryptophan|'\n","    r'tyrosine|iodine|iodo|granulocyte|albumin|insulin|heparin|collagen|'\n","    r'glucosamine|chondroitin|carnitine|taurine|inositol|choline|'\n","    r'ubiquinone|rutin|hesperidin|quercetin|lipoic|coenzyme|'\n","    r'lactobacillus|bifidobacterium|probiotic|prebiotic|'\n","    r'paracetamol|acetaminophen|ibuprofen|aspirin|caffeine|codeine|'\n","    r'amoxicillin|ampicillin|penicillin|ciprofloxacin|metronidazole|'\n","    r'metformin|atorvastatin|simvastatin|amlodipine|enalapril|losartan|'\n","    r'omeprazole|ranitidine|ondansetron|salbutamol|terbutaline|'\n","    r'prednisolone|dexamethasone|hydrocortisone|betamethasone|loratadine|'\n","    r'cetirizine|diazepam|alprazolam|fluoxetine|sertraline|levothyroxine|'\n","    r'warfarin|cyclosporine|methotrexate|sildenafil|testosterone|estradiol|'\n","    r'progesterone|spironolactone|dandelion|silymarin|retinol|tocopherol|'\n","    r'ascorbic|cholecalciferol|menadione'\n",")\n","UNSEPARATED_SPLIT_PATTERN = re.compile(\n","    r'(?<=[a-z\\d])\\s+(?=(' + _UNSEP + r')\\b)'\n",")\n","\n","# R3 — Dosage unit pattern\n","# Also catches embedded doses like \"collagen7000mg\", \"msm100mg\"\n","DOSE_UNIT_PATTERN = re.compile(\n","    r'\\d+(\\.\\d+)?\\s*(mg|g|gm|mcg|µg|ug|iu|i\\s*u|miu|ml|%|units?|tabs?|caps?|amp|vial)\\b',\n","    re.IGNORECASE\n",")\n","\n","# R3.1 — Leading numeric token pattern\n","LEADING_NUMBER_PATTERN = re.compile(\n","    r'^\\s*[\\d\\s\\.]+\\s*'\n","    r'(mg|g|gm|mcg|µg|ug|iu|i\\s*u|miu|ml|%|units?|tabs?|caps?|amp|vial)?\\s*$',\n","    re.IGNORECASE\n",")\n","\n","\n","# =============================================================================\n","# Logging\n","# =============================================================================\n","def log_message(message):\n","    \"\"\"Log messages to console and file with timestamp.\"\"\"\n","    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n","    msg = f\"[{timestamp}] {message}\"\n","    print(msg)\n","    try:\n","        with open(LOG_FILE, \"a\", encoding=\"utf-8\") as f:\n","            f.write(msg + \"\\n\")\n","    except Exception:\n","        pass\n","\n","\n","# =============================================================================\n","# Step 0 — Encoded Token Decoder\n","# =============================================================================\n","def decode_encoded_tokens(text):\n","    \"\"\"\n","    Replace __INGxxxx__ placeholders with known decoded values.\n","    Any remaining unknown tokens are replaced with a space (dropped).\n","    \"\"\"\n","    if not isinstance(text, str):\n","        return text\n","    for token, replacement in ENCODED_TOKEN_MAP.items():\n","        text = text.replace(token, replacement)\n","    text = re.sub(r'__[A-Z]+\\d+__', ' ', text)\n","    return text\n","\n","\n","# =============================================================================\n","# R4 — Spell Correction\n","# =============================================================================\n","def apply_spell_fix(text):\n","    \"\"\"\n","    Apply spell corrections using word-boundary regex. No synonym merging (P0.1).\n","    Uses \\b word boundaries so 'panthenoll' → 'panthenol' without\n","    'pantheno' re-matching inside the corrected word.\n","    Applies each correction independently (no cascading conflicts).\n","    \"\"\"\n","    if not isinstance(text, str):\n","        return text\n","    for wrong, right in sorted(SPELL_FIX.items(), key=lambda x: -len(x[0])):\n","        if wrong in text:\n","            text = re.sub(r'\\b' + re.escape(wrong) + r'\\b', right, text)\n","    return text\n","\n","\n","# =============================================================================\n","# Garbage Detection\n","# =============================================================================\n","def is_garbage_token(token):\n","    \"\"\"\n","    Return True if a single ingredient token should be discarded.\n","\n","    Rules:\n","      1. Empty or <= 2 chars  →  garbage\n","      2. Exact match in GARBAGE_EXACT  →  garbage\n","      3. Exact match in GARBAGE_TOKENS_EXACT  →  garbage\n","      4. Substring check against GARBAGE_EXACT phrases (8+ chars only)\n","    \"\"\"\n","    t = token.strip().lower()\n","    if not t or len(t) <= 2:\n","        return True\n","    if t in GARBAGE_EXACT:\n","        return True\n","    if t in GARBAGE_TOKENS_EXACT:\n","        return True\n","    if t in NON_DRUG_TOKENS:\n","        return True\n","    for g in GARBAGE_EXACT:\n","        if len(g) >= 8 and g in t:\n","            return True\n","    return False\n","\n","\n","def is_likely_garbage_phrase(text):\n","    \"\"\"\n","    Detect multi-word free-text with NO recognizable ingredient vocabulary.\n","    Returns True → discard the entire entry.\n","    \"\"\"\n","    words = text.lower().split()\n","    if len(words) < 3:\n","        return False\n","    matches = sum(\n","        1 for w in words\n","        if any(kw in w for kw in KNOWN_INGREDIENT_KEYWORDS)\n","    )\n","    return matches == 0\n","\n","\n","# =============================================================================\n","# R5 — Cosmetic Entry Detection\n","# =============================================================================\n","def is_cosmetic_entry(text):\n","    \"\"\"\n","    Return True if the entry looks like a cosmetic / personal-care product.\n","    Triggers when 2+ cosmetic terms are present. Row is DELETED.\n","    \"\"\"\n","    if not text:\n","        return False\n","    words = set(text.lower().split())\n","    return len(words & COSMETIC_TERMS) >= 2\n","\n","\n","# =============================================================================\n","# R6 — Vague Category Detection\n","# =============================================================================\n","def is_vague_category(text):\n","    \"\"\"Return True if the entire entry is a vague/non-specific category.\"\"\"\n","    if not text:\n","        return False\n","    t = text.strip().lower()\n","    if t in VAGUE_CATEGORY_EXACT:\n","        return True\n","    tokens = [p.strip() for p in t.split('+')]\n","    return all(tok in VAGUE_CATEGORY_EXACT for tok in tokens if tok)\n","\n","\n","# =============================================================================\n","# R7 — Truncated Token Detection\n","# =============================================================================\n","def has_truncated_token(parts):\n","    \"\"\"Return True if any part looks like a truncated/incomplete ingredient.\"\"\"\n","    for p in parts:\n","        p_lower = p.strip().lower()\n","        if p_lower in TRUNCATED_TOKENS:\n","            return True\n","        if re.match(r'^(hydro|mono|poly|peg|dehydro|desoxy|nor)$', p_lower):\n","            return True\n","    return False\n","\n","\n","# =============================================================================\n","# R8 — Unknown Token Classification\n","# =============================================================================\n","def classify_token(token):\n","    \"\"\"\n","    Returns:\n","      'valid'   — recognized ingredient token\n","      'unknown' — suspicious / unrecognized token (R8)\n","    \"\"\"\n","    t = token.strip().lower()\n","    if not t:\n","        return 'valid'\n","    if t in SHORT_VALID_TOKENS:\n","        return 'valid'\n","    if t.startswith('vitamin '):\n","        return 'valid'\n","    for kw in KNOWN_INGREDIENT_KEYWORDS:\n","        if kw in t:\n","            return 'valid'\n","    if t in SPELL_FIX.values():\n","        return 'valid'\n","    if UNKNOWN_TOKEN_PATTERN.match(t):\n","        return 'unknown'\n","    if len(t) <= 3 and t not in SHORT_VALID_TOKENS:\n","        return 'unknown'\n","    return 'valid'\n","\n","\n","# =============================================================================\n","# R11 — Omega Format Normalization\n","# omega-3 → omega 3 / omega-3-6-9 → omega 3 6 9\n","# =============================================================================\n","def normalize_omega(text):\n","    \"\"\"\n","    R11: Split omega combos into separate + tokens.\n","      omega-3        → omega 3\n","      omega-6        → omega 6\n","      omega-3-6-9    → omega 3 + omega 6 + omega 9\n","      omega-3-6      → omega 3 + omega 6\n","      omega 3 6 9    → omega 3 + omega 6 + omega 9  (space-separated form)\n","    \"\"\"\n","    # Multi-number with dashes: omega-3-6-9 → omega 3 + omega 6 + omega 9\n","    def expand_omega_multi(m):\n","        nums = m.group(1).split('-')\n","        return ' + '.join('omega ' + n for n in nums)\n","\n","    text = re.sub(r'\\bomega-(\\d+(?:-\\d+)+)\\b', expand_omega_multi, text)\n","\n","    # Single number with dash: omega-3 → omega 3\n","    text = re.sub(r'\\bomega-(\\d+)\\b', r'omega \\1', text)\n","\n","    # Space-separated multi: \"omega 3 6 9\" → omega 3 + omega 6 + omega 9\n","    def expand_omega_spaced(m):\n","        nums = m.group(1).strip().split()\n","        if len(nums) > 1:\n","            return ' + '.join('omega ' + n for n in nums)\n","        return 'omega ' + nums[0]\n","\n","    text = re.sub(r'\\bomega\\s+(\\d+(?:\\s+\\d+)+)\\b', expand_omega_spaced, text)\n","\n","    return text\n","\n","\n","# =============================================================================\n","# Text Normalization\n","# =============================================================================\n","def normalize_text(text):\n","    \"\"\"\n","    Full normalization pipeline:\n","      1.  Strip / null-check\n","      2.  Lowercase\n","      3.  R4  — Spell fix\n","      4.  Manual replacements (B-vitamins, vit. abbreviations)\n","      5.  R11 — Omega format normalization\n","      6.  Vitamin abbreviations\n","      7.  Remove 'amin/amins' artifacts (word-boundary only)\n","      8.  Brackets → separators\n","      9.  Insert '+' before 'vitamin' when missing\n","      10. Insert '+' between known unseparated ingredients\n","      11. R1  — Normalize all separators to ' + '\n","      12. R3  — Remove dosage strengths\n","      13. Remove special characters\n","      14. Clean whitespace / leading-trailing separators\n","    \"\"\"\n","    if pd.isna(text) or not isinstance(text, str):\n","        return None\n","\n","    text = text.strip()\n","    if not text or text.lower() in GARBAGE_EXACT:\n","        return None\n","\n","    text = text.lower()\n","\n","    # Step 3: R4 — Spell fix\n","    text = apply_spell_fix(text)\n","\n","    # Step 4a: Plain replacements (multi-word phrases first)\n","    for wrong, right in PLAIN_REPLACEMENTS.items():\n","        if wrong in text:\n","            text = text.replace(wrong, right)\n","\n","    # Step 4b: Word-boundary B-vitamin codes (longest first, prevents b1 inside b12)\n","    for pattern, right in BVITAMIN_REGEX:\n","        text = pattern.sub(right, text)\n","\n","    # Step 5: R11 — Omega normalization (before separator normalization)\n","    text = normalize_omega(text)\n","\n","    # Step 6: Vitamin abbreviations (catch any remaining vit. / vit not caught above)\n","    text = re.sub(r'\\bvit\\.?\\s+', 'vitamin ', text)\n","\n","    # Step 7: Remove 'amin/amins' artifacts AND bare 'vitamin' with nothing after it\n","    # word-boundary so 'thiamine' / 'vitamins' are NOT affected\n","    text = re.sub(r'\\bvitamin\\s+amins?\\b', 'vitamin', text)\n","    text = re.sub(r'\\bamins?\\b', '', text)\n","\n","    # Step 8: Brackets → separators\n","    text = re.sub(r'\\(([^)]*)\\)', r' + \\1', text)\n","\n","    # Step 9: Insert '+' before 'vitamin' when not already preceded by '+'\n","    text = re.sub(r'(?<!\\+)\\s+(vitamin\\s)', r' + \\1', text)\n","\n","    # Step 10: Insert '+' between known unseparated ingredients\n","    text = UNSEPARATED_SPLIT_PATTERN.sub(' + ', text)\n","\n","    # Step 11: R1 — Normalize all separators → ' + '\n","    text = re.sub(r'(--|–|-|/|,|;|\\|&| and | with |&|\\+)', ' + ', text)\n","\n","    # Step 12: R3 — Remove dosage strengths (mg, g, mcg, IU, ml, %, etc.)\n","    # FIRST: protect \"type N\" patterns using smart token-level context detection.\n","    # Rule:\n","    #   - If the FULL entry has a medical context word (vaccine, poliomyelitis, etc.)\n","    #     → protect all \"type N\" tokens (standalone or embedded).\n","    #   - If NO medical context found anywhere → strip all \"type N\".\n","    # This correctly handles:\n","    #   \"type 2 + vaccine inactivated poliomyelitis type 1\" → all type N kept (context present)\n","    #   \"type 1 + type 2 + type 3\"                         → all stripped (no context)\n","    _TYPE_MEDICAL_CONTEXT = {\n","        \"poliomyelitis\", \"poliovirus\", \"vaccine\", \"hepatitis\",\n","        \"diphtheria\", \"pertussis\", \"meningitis\", \"rotavirus\",\n","        \"herpes\", \"adenovirus\", \"coronavirus\", \"influenza\",\n","        \"dengue\", \"rabies\", \"typhoid\", \"cholera\",\n","        \"collagen\", \"diabetes\",\n","    }\n","    _full_has_type_context = any(kw in text for kw in _TYPE_MEDICAL_CONTEXT)\n","    _type_protected = {}\n","    def _protect_type_smart(m):\n","        if _full_has_type_context:\n","            key = \"__TYPEPROT\" + str(len(_type_protected)) + \"__\"\n","            _type_protected[key] = m.group(0).strip()\n","            return key\n","        return \" \"   # no context anywhere → strip\n","    text = re.sub(r'\\btype\\s+\\d+\\b', _protect_type_smart, text)\n","\n","    text = DOSE_UNIT_PATTERN.sub(' ', text)\n","    # Remove leftover multi-digit bare numbers (dose remnants like \"000\", \"500\")\n","    text = re.sub(r'\\b\\d{2,}\\b', ' ', text)\n","    # R3.3 — Remove trailing orphan digits after drug names\n","    # Handles: \"levobunolol hydrochloride 0 5\" → \"levobunolol hydrochloride\"\n","    # These are decimal doses split by removing the dot (0.5% → 0 5)\n","    text = re.sub(r'(?<=[a-z])\\s+\\d+(?:\\s+\\d+)*\\s*$', ' ', text)\n","    text = re.sub(r'(?<=[a-z])\\s+0\\s+\\d+', ' ', text)   # \"drug 0 5\" → \"drug\"\n","    text = re.sub(r'(?<=[a-z])\\s+\\d\\s+\\d+\\b', ' ', text)  # \"drug 2 5\" → \"drug\"\n","    # Strip lone single digit after drug name\n","    # But protect \"omega N\" and \"type N\" by temporarily replacing them\n","    text = re.sub(r'\\bomega\\s+(\\d)\\b', r'omega__OMGPROT__\\1', text)\n","    text = re.sub(r'\\btype\\s+(\\d)\\b', r'type__TYPROT__\\1', text)\n","    text = re.sub(r'(?<=[a-z])\\s+\\d\\b', ' ', text)   # \"drug 0\" → \"drug\"\n","    text = text.replace('omega__OMGPROT__', 'omega ')\n","    text = text.replace('type__TYPROT__', 'type ')\n","\n","    # Restore protected \"type N\" tokens\n","    for key, val in _type_protected.items():\n","        text = text.replace(key, val)\n","\n","    # Step 13: Remove special characters (keep letters, digits, spaces, +)\n","    text = re.sub(r'[^a-z0-9+\\s]', ' ', text)\n","\n","    # Step 14: Clean whitespace and separators\n","    text = re.sub(r'\\s+', ' ', text).strip()\n","    text = re.sub(r'\\s*\\+\\s*', ' + ', text).strip()\n","    text = text.strip('+ ')\n","\n","    return text if text else None\n","\n","\n","# =============================================================================\n","# Vitamin Shortcut Expansion\n","# =============================================================================\n","def expand_vitamin_shortcuts(parts, original_text):\n","    \"\"\"\n","    When the original text contained the word 'vitamin', expand lone\n","    vitamin-letter tokens:  c → vitamin c,  d3 → vitamin d3, etc.\n","    Only expands tokens that are in VALID_VITAMIN_LETTERS.\n","    \"\"\"\n","    out = []\n","    has_vitamin = \"vitamin\" in (original_text or \"\")\n","\n","    for p in parts:\n","        p = p.strip()\n","        if not p:\n","            continue\n","        if p.startswith(\"vitamin \"):\n","            out.append(p)\n","            continue\n","        if has_vitamin and p in VALID_VITAMIN_LETTERS:\n","            out.append(f\"vitamin {p}\")\n","        else:\n","            out.append(p)\n","\n","    return out\n","\n","\n","# =============================================================================\n","# R3.1 — Remove Leading Numeric Tokens\n","# =============================================================================\n","def remove_leading_numeric_tokens(parts):\n","    \"\"\"\n","    R3.1: Drop tokens from the START that are purely numeric or dose-only.\n","    Examples:\n","      [\"150\", \"alpha\", \"folic acid\"]  → [\"alpha\", \"folic acid\"]\n","      [\"000 i u\", \"vitamin d3\"]       → [\"vitamin d3\"]\n","      [\"1000\", \"folic acid\"]          → [\"folic acid\"]\n","    \"\"\"\n","    while parts:\n","        first = parts[0].strip()\n","        if LEADING_NUMBER_PATTERN.match(first):\n","            parts = parts[1:]\n","        elif re.match(r'^\\d+$', first):\n","            parts = parts[1:]\n","        else:\n","            break\n","    return parts\n","\n","\n","# =============================================================================\n","# Clean Individual Ingredients List\n","# =============================================================================\n","def clean_ingredient_list(parts, original_text):\n","    \"\"\"\n","    Given a list of raw ingredient tokens:\n","      1. Expand vitamin shortcuts\n","      2. R3.1 Remove leading numeric tokens\n","      3. Remove standalone 'amin/amins' noise\n","      4. Strip trailing spurious digits from drug names\n","      5. Filter garbage tokens\n","      6. R8  Classify unknown tokens\n","      7. Deduplicate + sort (intra-row only, P0.2)\n","\n","    Returns:\n","      (cleaned_parts, token_flags)\n","      token_flags: list of (token, 'UNKNOWN') for flagged tokens\n","    \"\"\"\n","    parts = expand_vitamin_shortcuts(parts, original_text)\n","    parts = remove_leading_numeric_tokens(parts)\n","\n","    cleaned     = []\n","    token_flags = []\n","\n","    for ingredient in parts:\n","        ingredient = re.sub(r'\\s+', ' ', ingredient).strip()\n","\n","        # Remove standalone 'amin' / 'amins' — word boundary only\n","        ingredient = re.sub(r'\\bamin[s]?\\b', '', ingredient).strip()\n","\n","        # Remove trailing digits that crept onto drug names (thiamine2 → thiamine)\n","        # Protected: vitamin codes like d3, k2, b12 already prefixed by expand_vitamin_shortcuts\n","        ingredient = re.sub(r'\\b([a-z]{4,})\\d+$', r'\\1', ingredient)\n","\n","        # Final whitespace cleanup\n","        ingredient = re.sub(r'\\s+', ' ', ingredient).strip()\n","\n","        if is_garbage_token(ingredient):\n","            continue\n","        if len(ingredient) <= 2:\n","            continue\n","\n","        # R8 — Token classification\n","        token_class = classify_token(ingredient)\n","        if token_class == 'unknown':\n","            token_flags.append((ingredient, 'UNKNOWN'))\n","\n","        cleaned.append(ingredient)\n","\n","    # Deduplicate + sort (intra-row only, P0.2)\n","    return sorted(set(cleaned)), token_flags\n","\n","\n","# =============================================================================\n","# Main Per-Row Cleaning Function\n","# =============================================================================\n","def clean_active_ingredient(text):\n","    \"\"\"\n","    Complete per-row pipeline:\n","      decode → normalize → garbage-phrase check → cosmetic check (R5)\n","      → split → R3.1 leading number → clean → R6/R7/R8 flags\n","      → V1-V4 validation → join\n","\n","    Returns dict:\n","      result        : cleaned string or None\n","      row_flag      : comma-separated flags\n","      unknown_tokens: list of UNKNOWN token strings\n","    \"\"\"\n","    row_flags      = []\n","    unknown_tokens = []\n","\n","    # Step 0: Decode encoded tokens BEFORE any other processing\n","    text = decode_encoded_tokens(text)\n","\n","    # Step 1: Normalize\n","    normalized = normalize_text(text)\n","    if normalized is None:\n","        return {\"result\": None, \"row_flag\": \"\", \"unknown_tokens\": []}\n","\n","    # Step 2: Discard unrecognizable free-text phrases\n","    if is_likely_garbage_phrase(normalized):\n","        return {\"result\": None, \"row_flag\": \"\", \"unknown_tokens\": []}\n","\n","    # Step 3: R5 — Discard cosmetic / personal-care entries (delete row)\n","    if is_cosmetic_entry(normalized):\n","        return {\"result\": None, \"row_flag\": \"COSMETIC\", \"unknown_tokens\": []}\n","\n","    # Step 4: Split on ' + '\n","    parts = [p.strip() for p in normalized.split('+')]\n","\n","    # Step 5: Clean each ingredient + collect R8 flags\n","    cleaned_parts, token_flags = clean_ingredient_list(parts, normalized)\n","\n","    # V3 — Empty row after cleaning → delete\n","    if not cleaned_parts:\n","        return {\"result\": None, \"row_flag\": \"\", \"unknown_tokens\": []}\n","\n","    # R6 — Vague category check (on final joined result)\n","    joined = \" + \".join(cleaned_parts)\n","    if is_vague_category(joined):\n","        row_flags.append(\"VAGUE_CATEGORY\")\n","\n","    # R7 — Truncated token check\n","    if has_truncated_token(cleaned_parts):\n","        row_flags.append(\"TRUNCATED\")\n","\n","    # R8 — Aggregate unknown token flags\n","    if token_flags:\n","        unknown_tokens = [t for t, _ in token_flags]\n","        row_flags.append(\"HAS_UNKNOWN_TOKENS\")\n","\n","    # V1 — Leading number guard (safety net after R3.1)\n","    if cleaned_parts and re.match(r'^\\d+', cleaned_parts[0]):\n","        row_flags.append(\"LEADING_NUMBER_UNRESOLVED\")\n","\n","    return {\n","        \"result\":         joined,\n","        \"row_flag\":       \",\".join(row_flags) if row_flags else \"\",\n","        \"unknown_tokens\": unknown_tokens,\n","    }\n","\n","\n","# =============================================================================\n","# Main Pipeline\n","# =============================================================================\n","def clean_drug_ingredients(input_path, output_path):\n","    \"\"\"Full drug-ingredient cleaning pipeline with logging and statistics.\"\"\"\n","    log_message(\"=\" * 70)\n","    log_message(\"DRUG INGREDIENT CLEANING PIPELINE v2 - STARTED\")\n","    log_message(\"=\" * 70)\n","\n","    # ── Load ──────────────────────────────────────────────────────────────────\n","    log_message(f\"Loading data from: {input_path}\")\n","    if not os.path.exists(input_path):\n","        raise FileNotFoundError(f\"Input file not found: {input_path}\")\n","\n","    df = pd.read_csv(input_path)\n","    initial_count = len(df)\n","    log_message(f\"Loaded {initial_count:,} rows\")\n","    log_message(f\"Available columns: {list(df.columns)}\")\n","\n","    # ── Find ingredient column ────────────────────────────────────────────────\n","    df.columns = df.columns.str.strip()\n","    possible_cols = [\n","        'ActiveIngredient', 'activeingredient', 'active_ingredient',\n","        'Generic Name', 'generic name', 'GenericName',\n","        'Ingredients', 'ingredients',\n","    ]\n","\n","    col_name = None\n","    for col in possible_cols:\n","        if col in df.columns:\n","            col_name = col\n","            break\n","\n","    if col_name is None:\n","        col_lower_map = {c.lower(): c for c in df.columns}\n","        for col in possible_cols:\n","            if col.lower() in col_lower_map:\n","                col_name = col_lower_map[col.lower()]\n","                break\n","\n","    if col_name is None:\n","        raise ValueError(\n","            f\"Active ingredient column not found. \"\n","            f\"Available columns: {list(df.columns)}\"\n","        )\n","\n","    log_message(f\"Found ingredient column: '{col_name}'\")\n","\n","    # ── Audit encoded tokens ──────────────────────────────────────────────────\n","    encoded_mask  = df[col_name].str.contains(r'__[A-Z]+\\d+__', na=False, regex=True)\n","    encoded_count = encoded_mask.sum()\n","    if encoded_count > 0:\n","        log_message(f\"Found {encoded_count:,} rows with encoded tokens — decoding...\")\n","        top_tokens = (\n","            df[encoded_mask][col_name]\n","            .str.findall(r'__[A-Z]+\\d+__')\n","            .explode()\n","            .value_counts()\n","            .head(20)\n","        )\n","        log_message(\"Top encoded tokens:\\n\" + top_tokens.to_string())\n","    else:\n","        log_message(\"No encoded tokens detected.\")\n","\n","    # ── Apply cleaning ────────────────────────────────────────────────────────\n","    log_message(\"Starting cleaning process...\")\n","    cleaning_results = df[col_name].apply(clean_active_ingredient)\n","\n","    df['activeingredient_clean'] = cleaning_results.apply(lambda x: x['result'])\n","    df['row_flag']               = cleaning_results.apply(lambda x: x['row_flag'])\n","    df['unknown_tokens']         = cleaning_results.apply(\n","        lambda x: \"|\".join(x['unknown_tokens']) if x['unknown_tokens'] else \"\"\n","    )\n","\n","    # Graph node column\n","    df['Graph_Node_Ingredient'] = df['activeingredient_clean']\n","\n","    # Metadata columns\n","    df['ingredient_count'] = df['Graph_Node_Ingredient'].apply(\n","        lambda x: len(x.split(' + ')) if pd.notna(x) else 0\n","    )\n","    df['is_combination'] = df['ingredient_count'] > 1\n","    df['combo_type'] = df['ingredient_count'].apply(\n","        lambda n: 'single' if n == 1 else ('combo' if n > 1 else np.nan)\n","    )\n","\n","    # ── V3/V4/V5 — Filter invalid / flagged rows ─────────────────────────────\n","    # Keep ONLY rows with no flag at all (empty row_flag = clean & verified)\n","    df_valid = df[\n","        df['Graph_Node_Ingredient'].notna() &\n","        (df['ingredient_count'] > 0) &\n","        (df['row_flag'] == \"\")\n","    ].reset_index(drop=True)\n","\n","    removed_count = initial_count - len(df_valid)\n","\n","    # ── Save ──────────────────────────────────────────────────────────────────\n","    # Drop internal flag columns from final output — clean rows only\n","    cols_to_drop = [c for c in ['row_flag', 'unknown_tokens'] if c in df_valid.columns]\n","    df_final = df_valid.drop(columns=cols_to_drop)\n","    df_final.to_csv(output_path, index=False, encoding='utf-8')\n","\n","    # ── Summary ───────────────────────────────────────────────────────────────\n","    log_message(\"\")\n","    log_message(\"=\" * 70)\n","    log_message(\"CLEANING COMPLETED SUCCESSFULLY!\")\n","    log_message(\"=\" * 70)\n","    log_message(f\"Total rows processed:     {initial_count:,}\")\n","    log_message(f\"Valid rows retained:      {len(df_valid):,}\")\n","    log_message(f\"Invalid rows removed:     {removed_count:,}  \"\n","                f\"({removed_count / initial_count * 100:.1f}%)\")\n","    log_message(f\"Single ingredients:       {(df_valid['combo_type'] == 'single').sum():,}\")\n","    log_message(f\"Combination drugs:        {(df_valid['combo_type'] == 'combo').sum():,}\")\n","    log_message(f\"Average ingredients:      {df_valid['ingredient_count'].mean():.2f}\")\n","    log_message(f\"Max ingredients in combo: {df_valid['ingredient_count'].max()}\")\n","\n","    # Flag statistics (computed before dropping flag columns)\n","    flag_series = df_valid['row_flag'].str.split(',', expand=True).stack()\n","    flag_counts = flag_series[flag_series != ''].value_counts()\n","    if not flag_counts.empty:\n","        log_message(\"\\nRow flag summary (all should be empty — shown for debug):\")\n","        for flag, cnt in flag_counts.items():\n","            log_message(f\"  {flag:<35s}: {cnt:,}\")\n","    else:\n","        log_message(\"\\nNo flagged rows in output (all clean).\")\n","\n","    log_message(\"\")\n","    log_message(f\"Output saved to: {output_path}\")\n","    log_message(\"=\" * 70)\n","\n","    return df_valid\n","\n","\n","# =============================================================================\n","# Sanity-Check Helper\n","# =============================================================================\n","def test_samples():\n","    \"\"\"\n","    Run the cleaning function on all known edge-case samples and print results.\n","    Run this before the full pipeline to verify correctness.\n","    \"\"\"\n","    samples = [\n","        # ── Original tests ────────────────────────────────────────────────────\n","        (\"selected theraputically active gereinigter honig\",\n","         None),\n","\n","        (\"biotin + folic acid + iron vitamin c folic acid vitamin thiamine + niacin + pantothenic acid + pyridoxine + riboflavin\",\n","         \"biotin + folic acid + iron + niacin + pantothenic acid + pyridoxine + riboflavin + thiamine + vitamin c\"),\n","\n","        (\"human normal immunoglobulins\",\n","         \"human normal immunoglobulin\"),\n","\n","        (\"iodochlorohydroxyquinoline\",\n","         \"iodochlorohydroxyquinoline\"),\n","\n","        (\"dr ey t\",\n","         None),\n","\n","        (\"calcium vitamin d3 vitamin k2 zinc boron copper manganese selenium magnesium\",\n","         \"boron + calcium + copper + magnesium + manganese + selenium + vitamin d3 + vitamin k2 + zinc\"),\n","\n","        (\"alpha ketoanalogue of amino acids + histidine + lysine + threonine + tryptophan + tyrosine\",\n","         \"alpha ketoanalogue of amino acids + histidine + lysine + threonine + tryptophan + tyrosine\"),\n","\n","        (\"granulocyte macrofage colony stimulating factor\",\n","         \"granulocyte macrophage colony stimulating factor\"),\n","\n","        (\"__ING0035__2 + dandelion + folic acid + selenium + silymarin + vitamin c + vitamin e + zinc\",\n","         \"dandelion + folic acid + selenium + silymarin + vitamin c + vitamin e + zinc\"),\n","\n","        (\"__ING0024__mins + __ING0035__2 + copper + folic acid + iodine + iron + niacin + pyridoxine + riboflavin + selenium + thiamine + zinc\",\n","         \"copper + folic acid + iodine + iron + niacin + pyridoxine + riboflavin + selenium + thiamine + zinc\"),\n","\n","        (\"350m + cream + hair + smooth + styling\",\n","         None),\n","\n","        (\"sp__ING0055__olactone\",\n","         \"spironolactone\"),\n","\n","        (\"__ING0024__mins\",\n","         None),\n","\n","        # ── R11 — Omega normalization ─────────────────────────────────────────\n","        (\"omega-3 + vitamin e\",\n","         \"omega 3 + vitamin e\"),\n","\n","        (\"omega-3-6-9 + vitamin c\",\n","         \"omega 3 + omega 6 + omega 9 + vitamin c\"),\n","\n","        # ── R3.1 — Leading number removal ─────────────────────────────────────\n","        (\"150 + alpha + folic acid + iron\",\n","         \"alpha + folic acid + iron\"),\n","\n","        (\"1000 + folic acid + vitamin b12\",\n","         \"cobalamin + folic acid\"),   # b12→cobalamin via BVITAMIN_REGEX\n","\n","        # ── R4 — Spell fix (no synonym merging) ───────────────────────────────\n","        (\"cholorohexidine\",\n","         \"chlorhexidine\"),\n","\n","        (\"digoxine\",\n","         \"digoxin\"),\n","\n","        (\"panthenoll\",\n","         \"panthenol\"),\n","\n","        # ── P0.1 — Synonyms must NOT be merged ───────────────────────────────\n","        (\"paracetamol\",\n","         \"paracetamol\"),\n","\n","        (\"acetaminophen\",\n","         \"acetaminophen\"),\n","\n","        # ── R5 — Cosmetic entries deleted ─────────────────────────────────────\n","        (\"cream + hair + smooth + styling\",\n","         None),\n","    ]\n","\n","    print(\"\\n\" + \"=\" * 80)\n","    print(\"SANITY CHECK — EDGE CASE SAMPLES\")\n","    print(\"=\" * 80)\n","\n","    passed = failed = 0\n","\n","    for raw, expected in samples:\n","        res    = clean_active_ingredient(raw)\n","        result = res['result']\n","        flag   = res['row_flag']\n","\n","        ok   = (result is None and expected is None) or (result == expected)\n","        icon = \"PASS\" if ok else \"FAIL\"\n","        passed += ok\n","        failed += (not ok)\n","\n","        print(f\"\\n[{icon}]\")\n","        print(f\"  INPUT   : {raw}\")\n","        print(f\"  OUTPUT  : {result}\")\n","        print(f\"  FLAGS   : {flag or '(none)'}\")\n","        if not ok:\n","            print(f\"  EXPECTED: {expected}\")\n","\n","    print(\"\\n\" + \"=\" * 80)\n","    print(f\"Results: {passed} passed, {failed} failed out of {len(samples)} tests\")\n","    print(\"=\" * 80 + \"\\n\")\n","    return failed == 0\n","\n","\n","# =============================================================================\n","# Encoded Token Audit Helper\n","# =============================================================================\n","def audit_encoded_tokens(input_path):\n","    \"\"\"\n","    Scan the raw dataset and print all unique encoded tokens found,\n","    with example rows, to help you complete ENCODED_TOKEN_MAP.\n","\n","    Usage (in notebook):\n","        audit_encoded_tokens(INPUT_FILE)\n","    \"\"\"\n","    df = pd.read_csv(input_path)\n","    df.columns = df.columns.str.strip()\n","\n","    possible_cols = [\n","        'ActiveIngredient', 'activeingredient', 'active_ingredient',\n","        'Generic Name', 'generic name', 'GenericName',\n","        'Ingredients', 'ingredients',\n","    ]\n","    col_name = None\n","    for col in possible_cols:\n","        if col in df.columns:\n","            col_name = col\n","            break\n","    if col_name is None:\n","        col_lower_map = {c.lower(): c for c in df.columns}\n","        for col in possible_cols:\n","            if col.lower() in col_lower_map:\n","                col_name = col_lower_map[col.lower()]\n","                break\n","    if col_name is None:\n","        print(\"Could not find ingredient column.\")\n","        return\n","\n","    mask         = df[col_name].str.contains(r'__[A-Z]+\\d+__', na=False, regex=True)\n","    affected     = df[mask][col_name]\n","    all_tokens   = affected.str.findall(r'__[A-Z]+\\d+__').explode()\n","    token_counts = all_tokens.value_counts()\n","\n","    print(\"\\n\" + \"=\" * 70)\n","    print(\"ENCODED TOKEN AUDIT\")\n","    print(\"=\" * 70)\n","    print(f\"Rows with encoded tokens: {mask.sum():,}\")\n","    print(f\"Unique token types:       {len(token_counts)}\\n\")\n","    print(token_counts.to_string())\n","    print(\"\\n--- EXAMPLE ROWS PER TOKEN ---\")\n","    for token in token_counts.index:\n","        examples = df[\n","            df[col_name].str.contains(re.escape(token), na=False)\n","        ][col_name].head(3).tolist()\n","        print(f\"\\n{token}  (count={token_counts[token]})\")\n","        for ex in examples:\n","            print(f\"  -> {ex}\")\n","    print(\"=\" * 70 + \"\\n\")\n","\n","\n","# =============================================================================\n","# Entry Point\n","# =============================================================================\n","if __name__ == \"__main__\":\n","    try:\n","        # Clear previous log\n","        if os.path.exists(LOG_FILE):\n","            os.remove(LOG_FILE)\n","\n","        # OPTIONAL: uncomment to discover all __INGxxxx__ tokens first\n","        # audit_encoded_tokens(INPUT_FILE)\n","\n","        # Sanity check — must pass before running full pipeline\n","        all_passed = test_samples()\n","        if not all_passed:\n","            print(\"WARNING: Some sanity checks failed. Review before proceeding.\\n\")\n","\n","        # Run full pipeline\n","        df_result = clean_drug_ingredients(INPUT_FILE, OUTPUT_FILE)\n","\n","        # Display sample output\n","        print(\"\\n\" + \"=\" * 70)\n","        print(\"SAMPLE CLEANED INGREDIENTS (First 15 rows)\")\n","        print(\"=\" * 70)\n","        sample = df_result[\n","            ['Graph_Node_Ingredient', 'ingredient_count', 'combo_type', 'row_flag']\n","        ].head(15)\n","        for idx, row in sample.iterrows():\n","            ingredient = row['Graph_Node_Ingredient']\n","            count      = row['ingredient_count']\n","            combo      = row['combo_type']\n","            flag       = row['row_flag'] or ''\n","            display    = ingredient if len(ingredient) <= 60 else ingredient[:57] + \"...\"\n","            flag_str   = f\" [{flag}]\" if flag else \"\"\n","            print(f\"{idx + 1:2d}. [{combo:6s}] ({count} ing){flag_str} {display}\")\n","\n","        print(\"=\" * 70)\n","        print(f\"\\nFull results saved to : {OUTPUT_FILE}\")\n","        print(f\"Detailed log saved to : {LOG_FILE}\")\n","        print(f\"\\nSTATISTICS SUMMARY:\")\n","        print(f\"   Total valid drugs : {len(df_result):,}\")\n","        print(f\"   Single ingredient : {(df_result['combo_type'] == 'single').sum():,}\")\n","        print(f\"   Combinations      : {(df_result['combo_type'] == 'combo').sum():,}\")\n","\n","    except Exception as e:\n","        log_message(f\"\\nERROR OCCURRED: {e}\")\n","        import traceback\n","        log_message(traceback.format_exc())\n","        print(f\"\\nError: {e}\")\n","        print(\"Check log file for details.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wm5Z5TjwsSEZ","executionInfo":{"status":"ok","timestamp":1771548531121,"user_tz":-120,"elapsed":292,"user":{"displayName":"amr ayman","userId":"04429226451778292758"}},"outputId":"8897040f-01fd-46a5-c27f-91e9f08bf8ab"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","SANITY CHECK — EDGE CASE SAMPLES\n","================================================================================\n","\n","[PASS]\n","  INPUT   : selected theraputically active gereinigter honig\n","  OUTPUT  : None\n","  FLAGS   : (none)\n","\n","[PASS]\n","  INPUT   : biotin + folic acid + iron vitamin c folic acid vitamin thiamine + niacin + pantothenic acid + pyridoxine + riboflavin\n","  OUTPUT  : biotin + folic acid + iron + niacin + pantothenic acid + pyridoxine + riboflavin + thiamine + vitamin c\n","  FLAGS   : (none)\n","\n","[PASS]\n","  INPUT   : human normal immunoglobulins\n","  OUTPUT  : human normal immunoglobulin\n","  FLAGS   : (none)\n","\n","[PASS]\n","  INPUT   : iodochlorohydroxyquinoline\n","  OUTPUT  : iodochlorohydroxyquinoline\n","  FLAGS   : (none)\n","\n","[PASS]\n","  INPUT   : dr ey t\n","  OUTPUT  : None\n","  FLAGS   : (none)\n","\n","[PASS]\n","  INPUT   : calcium vitamin d3 vitamin k2 zinc boron copper manganese selenium magnesium\n","  OUTPUT  : boron + calcium + copper + magnesium + manganese + selenium + vitamin d3 + vitamin k2 + zinc\n","  FLAGS   : (none)\n","\n","[PASS]\n","  INPUT   : alpha ketoanalogue of amino acids + histidine + lysine + threonine + tryptophan + tyrosine\n","  OUTPUT  : alpha ketoanalogue of amino acids + histidine + lysine + threonine + tryptophan + tyrosine\n","  FLAGS   : (none)\n","\n","[PASS]\n","  INPUT   : granulocyte macrofage colony stimulating factor\n","  OUTPUT  : granulocyte macrophage colony stimulating factor\n","  FLAGS   : (none)\n","\n","[PASS]\n","  INPUT   : __ING0035__2 + dandelion + folic acid + selenium + silymarin + vitamin c + vitamin e + zinc\n","  OUTPUT  : dandelion + folic acid + selenium + silymarin + vitamin c + vitamin e + zinc\n","  FLAGS   : (none)\n","\n","[PASS]\n","  INPUT   : __ING0024__mins + __ING0035__2 + copper + folic acid + iodine + iron + niacin + pyridoxine + riboflavin + selenium + thiamine + zinc\n","  OUTPUT  : copper + folic acid + iodine + iron + niacin + pyridoxine + riboflavin + selenium + thiamine + zinc\n","  FLAGS   : (none)\n","\n","[PASS]\n","  INPUT   : 350m + cream + hair + smooth + styling\n","  OUTPUT  : None\n","  FLAGS   : (none)\n","\n","[PASS]\n","  INPUT   : sp__ING0055__olactone\n","  OUTPUT  : spironolactone\n","  FLAGS   : (none)\n","\n","[PASS]\n","  INPUT   : __ING0024__mins\n","  OUTPUT  : None\n","  FLAGS   : (none)\n","\n","[PASS]\n","  INPUT   : omega-3 + vitamin e\n","  OUTPUT  : omega 3 + vitamin e\n","  FLAGS   : (none)\n","\n","[PASS]\n","  INPUT   : omega-3-6-9 + vitamin c\n","  OUTPUT  : omega 3 + omega 6 + omega 9 + vitamin c\n","  FLAGS   : (none)\n","\n","[PASS]\n","  INPUT   : 150 + alpha + folic acid + iron\n","  OUTPUT  : alpha + folic acid + iron\n","  FLAGS   : (none)\n","\n","[PASS]\n","  INPUT   : 1000 + folic acid + vitamin b12\n","  OUTPUT  : cobalamin + folic acid\n","  FLAGS   : (none)\n","\n","[PASS]\n","  INPUT   : cholorohexidine\n","  OUTPUT  : chlorhexidine\n","  FLAGS   : (none)\n","\n","[PASS]\n","  INPUT   : digoxine\n","  OUTPUT  : digoxin\n","  FLAGS   : (none)\n","\n","[PASS]\n","  INPUT   : panthenoll\n","  OUTPUT  : panthenol\n","  FLAGS   : (none)\n","\n","[PASS]\n","  INPUT   : paracetamol\n","  OUTPUT  : paracetamol\n","  FLAGS   : (none)\n","\n","[PASS]\n","  INPUT   : acetaminophen\n","  OUTPUT  : acetaminophen\n","  FLAGS   : (none)\n","\n","[PASS]\n","  INPUT   : cream + hair + smooth + styling\n","  OUTPUT  : None\n","  FLAGS   : (none)\n","\n","================================================================================\n","Results: 23 passed, 0 failed out of 23 tests\n","================================================================================\n","\n","[2026-02-20 00:48:56] ======================================================================\n","[2026-02-20 00:48:56] DRUG INGREDIENT CLEANING PIPELINE v2 - STARTED\n","[2026-02-20 00:48:56] ======================================================================\n","[2026-02-20 00:48:56] Loading data from: /content/drive/MyDrive/DataDoseDepi/DataDoseDataset.csv\n","[2026-02-20 00:48:56] \n","ERROR OCCURRED: Input file not found: /content/drive/MyDrive/DataDoseDepi/DataDoseDataset.csv\n","[2026-02-20 00:48:56] Traceback (most recent call last):\n","  File \"/tmp/ipython-input-2960700495.py\", line 1138, in <cell line: 0>\n","    df_result = clean_drug_ingredients(INPUT_FILE, OUTPUT_FILE)\n","                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/tmp/ipython-input-2960700495.py\", line 829, in clean_drug_ingredients\n","    raise FileNotFoundError(f\"Input file not found: {input_path}\")\n","FileNotFoundError: Input file not found: /content/drive/MyDrive/DataDoseDepi/DataDoseDataset.csv\n","\n","\n","Error: Input file not found: /content/drive/MyDrive/DataDoseDepi/DataDoseDataset.csv\n","Check log file for details.\n"]}]}]}